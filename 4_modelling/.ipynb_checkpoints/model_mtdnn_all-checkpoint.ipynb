{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c1078f",
   "metadata": {},
   "source": [
    "# Multi-Task Deep Neural Network\n",
    "This is a deep learning model that is trained to predict multiple outputs simultaneously. It can be used for both categorical and numerical target variables.   \n",
    "\n",
    "**_bayesian hyperparameter tuning_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e2118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 'all', 'vif_5' or 'vif_10'\n",
    "vif = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efae422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import platform\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt import gp_minimize, space\n",
    "import sys\n",
    "\n",
    "from validation import cross_validation\n",
    "from validation import performance_test_fixed\n",
    "from validation import performance_test_shifted\n",
    "\n",
    "date_format = \"%Y-%m-%d\"\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47bd36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_os = platform.system()\n",
    "print(\"OS in my system: \",my_os)\n",
    "\n",
    "if my_os == \"Windows\":\n",
    "    path = str(pathlib.Path().absolute()) + '\\\\'\n",
    "    slash = '\\\\'\n",
    "else:\n",
    "    path = str(pathlib.Path().absolute()) + '/'\n",
    "    slash = '/'\n",
    "\n",
    "path_3 = path.replace('4_modelling', '3_data_pre-processing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910f8ca5",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c329743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path_3 + 'data_artifacts' + slash + 'data_set_e_spx_3-' + vif + '.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a19307",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------\n",
    "# FIRST TRY WITH MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6663143",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_target = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5cf0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_head_drop = ['tau_target', 'symbol', 'ric', 'year', 'fam_target_clayton', 'fam_target_frank', 'fam_target_gaussian',\n",
    "            'fam_target_gumbel', 'fam_target_indep', 'fam_target_joe', 'fam_target_student','fam_target', 'naics']\n",
    "y_head_multi_target = ['tau_target', 'fam_target_clayton', 'fam_target_frank', 'fam_target_gaussian', 'fam_target_gumbel',\n",
    "                    'fam_target_indep', 'fam_target_joe', 'fam_target_student']\n",
    "y_head_single_target = ['tau_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train = data[(data['year'] >= (2000)) & (data['year'] <= (2018))]\n",
    "test = data[(data['year'] >= (2019)) & (data['year'] <= (2020))]\n",
    "\n",
    "X_train = train.drop(columns=X_head_drop)\n",
    "X_test = test.drop(columns=X_head_drop)\n",
    "\n",
    "if multi_target == False:\n",
    "    y_train = train[y_head_single_target]\n",
    "    y_test = test[y_head_single_target]\n",
    "else:\n",
    "    y_train = train[y_head_multi_target]\n",
    "    y_test = test[y_head_multi_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34539ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d482c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that you can also omit the `input_shape` argument.\n",
    "# In that case the model doesn't have any weights until the first call\n",
    "# to a training/evaluation method (since it isn't yet built):\n",
    "model = Sequential()\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(4))\n",
    "# model.weights not created yet\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca55ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3cab62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, TimeDistributed, Dense\n",
    "\n",
    "# Define the number of input sequences and the number of features for each sequence\n",
    "n_input_sequences = 5\n",
    "n_features = 3\n",
    "\n",
    "# Define the inputs for each sequence\n",
    "inputs = [Input(shape=(None, n_features)) for _ in range(n_input_sequences)]\n",
    "\n",
    "# Create a shared LSTM layer to handle all input sequences\n",
    "lstm = LSTM(64)\n",
    "encoded = [lstm(input_) for input_ in inputs]\n",
    "\n",
    "# Apply a TimeDistributed layer to each encoded sequence\n",
    "output = [TimeDistributed(Dense(1))(encoded_i) for encoded_i in encoded]\n",
    "\n",
    "# Combine the outputs into a single model\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b507ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844cac8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6146c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='relu', input_dim=100))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed06cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "    y = data[:, 0]\n",
    "    x = data[:, 1:]\n",
    "    return x, y.astype(int)\n",
    "\n",
    "\n",
    "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
    "\n",
    "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
    "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e0a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(x_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3bb49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bdbc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8dd5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3dc406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd95824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78cd4087",
   "metadata": {},
   "source": [
    "test mixture of categorical and numerical target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de763efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51d44725",
   "metadata": {},
   "source": [
    "There are several Python packages that can be used to implement multi-task deep neural networks (MT-DNNs) for multi-task learning. Some popular ones include:\n",
    "\n",
    "- Keras: Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It provides a simple and user-friendly interface to create MT-DNNs with multiple output layers.\n",
    "\n",
    "- PyTorch: PyTorch is an open-source machine learning library based on the Torch library. It provides a flexible and user-friendly interface to create MT-DNNs with multiple output layers.\n",
    "\n",
    "- TensorFlow: TensorFlow is an open-source machine learning library developed by Google. It provides a comprehensive and flexible interface to create MT-DNNs with multiple output layers, using the Keras API or the low-level TensorFlow API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30467d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
